{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohappyeyeballs==2.4.0 (from -r requirements.txt (line 1))\n",
      "  Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiohttp==3.10.5 (from -r requirements.txt (line 2))\n",
      "  Using cached aiohttp-3.10.5-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting aiosignal==1.3.1 (from -r requirements.txt (line 3))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting annotated-types==0.7.0 (from -r requirements.txt (line 4))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting anyio==4.4.0 (from -r requirements.txt (line 5))\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting async-timeout==4.0.3 (from -r requirements.txt (line 6))\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting attrs==24.2.0 (from -r requirements.txt (line 7))\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting beautifulsoup4==4.12.3 (from -r requirements.txt (line 8))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting certifi==2024.8.30 (from -r requirements.txt (line 9))\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset-normalizer==3.3.2 (from -r requirements.txt (line 10))\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting click==8.1.7 (from -r requirements.txt (line 11))\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting dataclasses-json==0.6.7 (from -r requirements.txt (line 12))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting Deprecated==1.2.14 (from -r requirements.txt (line 13))\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson==1.0.8 (from -r requirements.txt (line 14))\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting distro==1.9.0 (from -r requirements.txt (line 15))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting dnspython==2.6.1 (from -r requirements.txt (line 16))\n",
      "  Using cached dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting eval_type_backport==0.2.0 (from -r requirements.txt (line 17))\n",
      "  Using cached eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting exceptiongroup==1.2.2 (from -r requirements.txt (line 18))\n",
      "  Using cached exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting faiss-cpu==1.8.0.post1 (from -r requirements.txt (line 19))\n",
      "  Using cached faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting filelock==3.16.0 (from -r requirements.txt (line 20))\n",
      "  Using cached filelock-3.16.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting frozenlist==1.4.1 (from -r requirements.txt (line 21))\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting fsspec==2024.9.0 (from -r requirements.txt (line 22))\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting greenlet==3.0.3 (from -r requirements.txt (line 23))\n",
      "  Using cached greenlet-3.0.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting h11==0.14.0 (from -r requirements.txt (line 24))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httpcore==1.0.5 (from -r requirements.txt (line 25))\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting httpx==0.27.2 (from -r requirements.txt (line 26))\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting huggingface-hub==0.24.7 (from -r requirements.txt (line 27))\n",
      "  Using cached huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting idna==3.8 (from -r requirements.txt (line 28))\n",
      "  Using cached idna-3.8-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting Jinja2==3.1.4 (from -r requirements.txt (line 29))\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jiter==0.5.0 (from -r requirements.txt (line 30))\n",
      "  Using cached jiter-0.5.0-cp312-none-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting joblib==1.4.2 (from -r requirements.txt (line 31))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting jsons==1.6.3 (from -r requirements.txt (line 32))\n",
      "  Using cached jsons-1.6.3-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting llama-cloud==0.0.17 (from -r requirements.txt (line 33))\n",
      "  Using cached llama_cloud-0.0.17-py3-none-any.whl.metadata (751 bytes)\n",
      "Collecting llama-index==0.11.9 (from -r requirements.txt (line 34))\n",
      "  Using cached llama_index-0.11.9-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai==0.3.1 (from -r requirements.txt (line 35))\n",
      "  Using cached llama_index_agent_openai-0.3.1-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-cli==0.3.1 (from -r requirements.txt (line 36))\n",
      "  Using cached llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core==0.11.9 (from -r requirements.txt (line 37))\n",
      "  Using cached llama_index_core-0.11.9-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-huggingface==0.3.1 (from -r requirements.txt (line 38))\n",
      "  Using cached llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl.metadata (718 bytes)\n",
      "Collecting llama-index-embeddings-openai==0.2.4 (from -r requirements.txt (line 39))\n",
      "  Using cached llama_index_embeddings_openai-0.2.4-py3-none-any.whl.metadata (635 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud==0.3.0 (from -r requirements.txt (line 40))\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy==0.9.48.post3 (from -r requirements.txt (line 41))\n",
      "  Using cached llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-ollama==0.3.1 (from -r requirements.txt (line 42))\n",
      "  Using cached llama_index_llms_ollama-0.3.1-py3-none-any.whl.metadata (668 bytes)\n",
      "Collecting llama-index-llms-openai==0.2.3 (from -r requirements.txt (line 43))\n",
      "  Using cached llama_index_llms_openai-0.2.3-py3-none-any.whl.metadata (654 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai==0.2.0 (from -r requirements.txt (line 44))\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai==0.2.0 (from -r requirements.txt (line 45))\n",
      "  Using cached llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
      "Collecting llama-index-question-gen-openai==0.2.0 (from -r requirements.txt (line 46))\n",
      "  Using cached llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file==0.2.1 (from -r requirements.txt (line 47))\n",
      "  Using cached llama_index_readers_file-0.2.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse==0.3.0 (from -r requirements.txt (line 48))\n",
      "  Using cached llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-index-vector-stores-faiss==0.2.1 (from -r requirements.txt (line 49))\n",
      "  Using cached llama_index_vector_stores_faiss-0.2.1-py3-none-any.whl.metadata (609 bytes)\n",
      "Collecting llama-parse==0.5.3 (from -r requirements.txt (line 50))\n",
      "  Using cached llama_parse-0.5.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting markdown-it-py==3.0.0 (from -r requirements.txt (line 51))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting MarkupSafe==2.1.5 (from -r requirements.txt (line 52))\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting marshmallow==3.22.0 (from -r requirements.txt (line 53))\n",
      "  Using cached marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting mdurl==0.1.2 (from -r requirements.txt (line 54))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting minijinja==2.2.0 (from -r requirements.txt (line 55))\n",
      "  Using cached minijinja-2.2.0-cp38-abi3-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting mpmath==1.3.0 (from -r requirements.txt (line 56))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting multidict==6.1.0 (from -r requirements.txt (line 57))\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting mypy-extensions==1.0.0 (from -r requirements.txt (line 58))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in c:\\deammy\\deam\\1-work\\indiv_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 59)) (1.6.0)\n",
      "Collecting networkx==3.3 (from -r requirements.txt (line 60))\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk==3.9.1 (from -r requirements.txt (line 61))\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy==1.26.4 (from -r requirements.txt (line 62))\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from -r requirements.txt (line 63))\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from -r requirements.txt (line 64))\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from -r requirements.txt (line 65))\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from -r requirements.txt (line 66))\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from -r requirements.txt (line 67))\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from -r requirements.txt (line 68))\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from -r requirements.txt (line 69))\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from -r requirements.txt (line 70))\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from -r requirements.txt (line 71))\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12 (from -r requirements.txt (line 72))\n",
      "  Downloading nvidia-nccl-cu12-0.0.1.dev5.tar.gz (4.3 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [31 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"c:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"c:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\เธ\\x8aเธขเธ\\x9eเธฑเธ—เธ\\x98เน\\x8c\\AppData\\Local\\Temp\\pip-build-env-0oogyjku\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 332, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=[])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\เธ\\x8aเธขเธ\\x9eเธฑเธ—เธ\\x98เน\\x8c\\AppData\\Local\\Temp\\pip-build-env-0oogyjku\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 302, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\เธ\\x8aเธขเธ\\x9eเธฑเธ—เธ\\x98เน\\x8c\\AppData\\Local\\Temp\\pip-build-env-0oogyjku\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 503, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\เธ\\x8aเธขเธ\\x9eเธฑเธ—เธ\\x98เน\\x8c\\AppData\\Local\\Temp\\pip-build-env-0oogyjku\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 318, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 152, in <module>\n",
      "      RuntimeError:\n",
      "      ###########################################################################################\n",
      "      The package you are trying to install is only a placeholder project on PyPI.org repository.\n",
      "      This package is hosted on NVIDIA Python Package Index.\n",
      "      \n",
      "      This package can be installed as:\n",
      "      ```\n",
      "      $ pip install nvidia-pyindex\n",
      "      $ pip install nvidia-nccl-cu12\n",
      "      ```\n",
      "      ###########################################################################################\n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 sentencepiece sentence-transformers numpy pandas faiss-cpu python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtogether\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Together\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPyPDF2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfReader\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceSplitter\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\__init__.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmock_embed_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MockEmbedding\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# indices\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# loading\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     ComposableGraph,\n\u001b[0;32m     21\u001b[0m     DocumentSummaryIndex,\n\u001b[0;32m     22\u001b[0m     GPTDocumentSummaryIndex,\n\u001b[0;32m     23\u001b[0m     GPTKeywordTableIndex,\n\u001b[0;32m     24\u001b[0m     GPTListIndex,\n\u001b[0;32m     25\u001b[0m     GPTRAKEKeywordTableIndex,\n\u001b[0;32m     26\u001b[0m     GPTSimpleKeywordTableIndex,\n\u001b[0;32m     27\u001b[0m     GPTTreeIndex,\n\u001b[0;32m     28\u001b[0m     GPTVectorStoreIndex,\n\u001b[0;32m     29\u001b[0m     KeywordTableIndex,\n\u001b[0;32m     30\u001b[0m     KnowledgeGraphIndex,\n\u001b[0;32m     31\u001b[0m     PropertyGraphIndex,\n\u001b[0;32m     32\u001b[0m     ListIndex,\n\u001b[0;32m     33\u001b[0m     RAKEKeywordTableIndex,\n\u001b[0;32m     34\u001b[0m     SimpleKeywordTableIndex,\n\u001b[0;32m     35\u001b[0m     SummaryIndex,\n\u001b[0;32m     36\u001b[0m     TreeIndex,\n\u001b[0;32m     37\u001b[0m     VectorStoreIndex,\n\u001b[0;32m     38\u001b[0m     load_graph_from_storage,\n\u001b[0;32m     39\u001b[0m     load_index_from_storage,\n\u001b[0;32m     40\u001b[0m     load_indices_from_storage,\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# structured\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     45\u001b[0m     SQLDocumentContextBuilder,\n\u001b[0;32m     46\u001b[0m )\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\__init__.py:32\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPTListIndex, ListIndex, SummaryIndex\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlist\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     GPTListIndex,\n\u001b[0;32m     29\u001b[0m     ListIndex,\n\u001b[0;32m     30\u001b[0m     SummaryIndex,\n\u001b[0;32m     31\u001b[0m )\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     load_graph_from_storage,\n\u001b[0;32m     34\u001b[0m     load_index_from_storage,\n\u001b[0;32m     35\u001b[0m     load_indices_from_storage,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulti_modal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiModalVectorStoreIndex\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     GPTPandasIndex,\n\u001b[0;32m     40\u001b[0m     PandasIndex,\n\u001b[0;32m     41\u001b[0m )\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\loading.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseIndex\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomposability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComposableGraph\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m INDEX_STRUCT_TYPE_TO_INDEX_CLASS\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StorageContext\n\u001b[0;32m      9\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\registry.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge_graph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KnowledgeGraphIndex\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlist\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryIndex\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulti_modal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiModalVectorStoreIndex\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperty_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PropertyGraphIndex\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PandasIndex\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\multi_modal\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Vector-store based data structures.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulti_modal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiModalVectorStoreIndex\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulti_modal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     MultiModalVectorIndexRetriever,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiModalVectorStoreIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiModalVectorIndexRetriever\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\multi_modal\\base.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMType\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulti_modal_llms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiModalLLM\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulti_modal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleMultiModalQueryEngine\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseNode, ImageNode, TextNode\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msettings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Settings\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\query_engine\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_query_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseQueryEngine\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# SQL\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql_query\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     NLSQLTableQueryEngine,\n\u001b[0;32m      6\u001b[0m     PGVectorSQLQueryEngine,\n\u001b[0;32m      7\u001b[0m     SQLTableRetrieverQueryEngine,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcitation_query_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CitationQueryEngine\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcogniswitch_query_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     CogniswitchQueryEngine,\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\struct_store\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson_query\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JSONQueryEngine\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     GPTPandasIndex,\n\u001b[0;32m      6\u001b[0m     PandasIndex,\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     GPTSQLStructStoreIndex,\n\u001b[0;32m     10\u001b[0m     SQLContextContainerBuilder,\n\u001b[0;32m     11\u001b[0m     SQLStructStoreIndex,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql_query\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     GPTNLStructStoreQueryEngine,\n\u001b[0;32m     15\u001b[0m     GPTSQLStructStoreQueryEngine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     SQLTableRetrieverQueryEngine,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     22\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSQLStructStoreIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSQLContextContainerBuilder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNLSQLTableQueryEngine\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     36\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\struct_store\\sql.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_structs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLStructTable\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLContextContainer\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     SQLStructDatapointExtractor,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseStructStoreIndex\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainer_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     SQLContextContainerBuilder,\n\u001b[0;32m     17\u001b[0m )\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\common\\struct_store\\sql.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Optional, cast\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_structs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StructDatapoint\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     OUTPUT_PARSER_TYPE,\n\u001b[0;32m      8\u001b[0m     BaseStructDatapointExtractor,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasePromptTemplate\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\common\\struct_store\\base.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseNode, MetadataMode\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msettings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLDatabase\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m truncate_text\n\u001b[0;32m     27\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\llama_index\\core\\utilities\\sql_wrapper.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"SQL wrapper around SQLDatabase in langchain.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, List, Optional, Tuple\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetaData, create_engine, insert, inspect, text\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Engine\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OperationalError, ProgrammingError\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\sqlalchemy\\__init__.py:12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util \u001b[38;5;28;01mas\u001b[39;00m _util\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdaptedConnection \u001b[38;5;28;01mas\u001b[39;00m AdaptedConnection\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseRow \u001b[38;5;28;01mas\u001b[39;00m BaseRow\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\sqlalchemy\\util\\__init__.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preloaded \u001b[38;5;28;01mas\u001b[39;00m preloaded\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_collections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coerce_generator_arg \u001b[38;5;28;01mas\u001b[39;00m coerce_generator_arg\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_collections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coerce_to_immutabledict \u001b[38;5;28;01mas\u001b[39;00m coerce_to_immutabledict\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_collections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m column_dict \u001b[38;5;28;01mas\u001b[39;00m column_dict\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\sqlalchemy\\util\\_collections.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ValuesView\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mweakref\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_has_cy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HAS_CYEXTENSION\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_non_string_iterable\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\sqlalchemy\\util\\_has_cy.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m         \u001b[43m_import_cy_extensions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     34\u001b[0m         HAS_CYEXTENSION \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Deammy\\Deam\\1-Work\\indiv_llm\\.venv\\Lib\\site-packages\\sqlalchemy\\util\\_has_cy.py:17\u001b[0m, in \u001b[0;36m_import_cy_extensions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_import_cy_extensions\u001b[39m():\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# all cython extension extension modules are treated as optional by the\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# setup, so to ensure that all are compiled, all should be imported here\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcyextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collections\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcyextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m immutabledict\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcyextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m processors\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcyextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resultproxy\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:645\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from together import Together\n",
    "from PyPDF2 import PdfReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import (\n",
    "    Settings\n",
    ")\n",
    "# from llama_index.core.retrievers import QueryFusionRetriever\n",
    "# from llama_index.core.memory import ChatMemoryBuffer\n",
    "# from unicodedata import normalize\n",
    "# from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "import numpy as np\n",
    "d = 1536  # dimension\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "# uri = os.environ.get(\"MONGO_DB\")\n",
    "# Create a new client and connect to the server\n",
    "# client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# def connect_mongo(uri):\n",
    "#     try:\n",
    "#         client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "#         print(\"Connect Success\")\n",
    "#         return client\n",
    "#     except:\n",
    "#         print(\"Connection Error\")\n",
    "#         return None\n",
    "\n",
    "# connect_mongo(uri)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiTurn RAG CLASS\n",
    "\n",
    "<p>This Version is demo, you can adapt all of it but be caeful of credit will be used.</p>\n",
    "\n",
    "----\n",
    "\n",
    "<strong>All Function</strong>\n",
    " \n",
    "``` def __init__ :```\n",
    "\n",
    "<p>document_path : Path to document.</br>\n",
    "        history : Keep chat history with list</br>\n",
    "        context_length : Determine length of context that query from retriever.</p>\n",
    "</br>\n",
    "\n",
    "\n",
    "``` def initial_retriever :```\n",
    "\n",
    "<p>initialize retriever for retriever document.</br></p>\n",
    "</br>\n",
    "\n",
    "\n",
    "``` def prepare_context :```\n",
    "\n",
    "<p>get context from retriever</br></p>\n",
    "</br>\n",
    "\n",
    "\n",
    "``` def update_history :```\n",
    "\n",
    "<p>store history chat to self.history</br></p>\n",
    "</br>\n",
    "\n",
    "\n",
    "``` def generate_response :```\n",
    "\n",
    "<p>get response from llm model.</br></p>\n",
    "</br>\n",
    "\n",
    "\n",
    "``` def get_response :```\n",
    "\n",
    "<p>get user input and prepare data, then get response from LLM.</br></p>\n",
    "</br>\n",
    "\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'together'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtogether\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Together\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'together'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    class : MultiturnRAG\n",
    "        init :\n",
    "            document_path : Path to document.\n",
    "            history : Keep chat history with list\n",
    "            context_length : Determine length of context that query from retriever.\n",
    "\n",
    "        def initial_retriever:\n",
    "            initialize retriever for retriever document.\n",
    "\n",
    "        def prepare_context:\n",
    "            get context from retriever\n",
    "\n",
    "        def update_history:\n",
    "            store history chat to self.history\n",
    "\n",
    "        def generate_response:\n",
    "            get response from llm model.\n",
    "\n",
    "        def get_response:\n",
    "            get user input and prepare data, then get response from LLM.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class MultiturnRAG:\n",
    "    def __init__(self,model, client, document_path: list, context_length : int = 20):\n",
    "        self.document_path = document_path\n",
    "        self.history = []\n",
    "        self.context_length = context_length\n",
    "        self.model = model\n",
    "        self.client = client\n",
    "        self.context = \"\"\n",
    "        \n",
    "    def initial_retriever(self):\n",
    "\n",
    "        \"\"\"Initila Retriever\n",
    "\n",
    "        input: -      \n",
    "        output: -\n",
    "    \n",
    "        \"\"\"\n",
    "\n",
    "        splitter = SentenceSplitter(chunk_size=500, chunk_overlap=100)\n",
    "        \n",
    "        text = \"\"\n",
    "        all_segment = []\n",
    "        for path in self.document_path:\n",
    "            reader = PdfReader(path)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "            segment = splitter.split_text(text)\n",
    "            for seg in segment:\n",
    "                all_segment.append(seg)\n",
    "\n",
    "        df = pd.DataFrame(all_segment, columns = [\"Text\"])\n",
    "        print(\"Pass : 1\")\n",
    "        df['Embedding'] = df['Text'].apply(model.encode)\n",
    "        vector = model.encode(df['Text'])\n",
    "        dim = vector.shape[1]\n",
    "        index = faiss.IndexFlatL2(dim)\n",
    "        index.add(vector)\n",
    "        self.retriever = index\n",
    "        self.df = df\n",
    "\n",
    "\n",
    "    def prepare_context(self, query):\n",
    "\n",
    "        \"\"\"Prepare Context\n",
    "\n",
    "        input:\n",
    "        query : input text for query document in retriever.\n",
    "        \n",
    "        output:\n",
    "        context : context from document that relate to query.\n",
    "    \n",
    "        \"\"\"\n",
    "\n",
    "        encode_pre = model.encode(query)\n",
    "        svec = np.array(encode_pre).reshape(1,-1)\n",
    "        print(\"Pass : 3\")\n",
    "        distance,pos = self.retriever.search(svec,k=2)\n",
    "\n",
    "        return self.df.Text.iloc[pos[0]]\n",
    "    \n",
    "    def update_history(self, user_input, bot_response):\n",
    "\n",
    "        \"\"\"Update History\n",
    "\n",
    "        input:\n",
    "        user_input : input text from user.\n",
    "        sys_response : response from llm.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        self.history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        self.history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "        if(len(self.history) == 6):\n",
    "            print(\"Rechat : \")\n",
    "            chat = \"\\n\".join([str(history) for history in self.history])\n",
    "            qa_prompt_str = f\"\"\"\n",
    "                Context information is below.\n",
    "                ---------------------\n",
    "                {self.context}\n",
    "                ---------------------\n",
    "                Conclude this conversation\n",
    "                {chat}\n",
    "            \"\"\"\n",
    "\n",
    "            \n",
    "            message = [{\"role\": \"system\", \"content\": \"You are a helpful assistant. You must conclude this conversation.\", \"context\" : self.context}]\n",
    "            for history in self.history:\n",
    "                message.append(history)\n",
    "            message.append({\"role\": \"user\", \"content\": qa_prompt_str})\n",
    "\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=message,\n",
    "                max_tokens=128,\n",
    "                temperature=0.7,\n",
    "                top_p=0.7,\n",
    "                top_k=50,\n",
    "                repetition_penalty=1,\n",
    "                stop=[\"[/INST]\",\"</s>\"],\n",
    "            )\n",
    "            print(dict(dict(dict(response)['choices'][0])['message'])['content'].split(\"im_end\")[0].replace(\"im_start\", \"\").replace(\"assistant\",\"\").replace(\"<\",\"\").replace(\">\",\"\").replace(\"|\",\"\"))\n",
    "            self.context = dict(dict(dict(response)['choices'][0])['message'])['content'].split(\"im_end\")[0].replace(\"im_start\", \"\").replace(\"assistant\",\"\").replace(\"<\",\"\").replace(\">\",\"\").replace(\"|\",\"\")\n",
    "            self.history = []\n",
    "\n",
    "        \n",
    "    def generate_response(self, input, query_context):\n",
    "\n",
    "        \"\"\"Generate response\n",
    "        \n",
    "        input :\n",
    "        input : text that will send to llm.\n",
    "        context : context document from retriever.\n",
    "        \n",
    "        output\n",
    "        response : response from llm.\n",
    "        \"\"\"\n",
    "\n",
    "        input = input.replace(\"\\b\", \"\")\n",
    "\n",
    "        print(self.context)\n",
    "        if(self.context == \"\"):\n",
    "            message = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}] #You communicate in Thai language.\n",
    "        else:\n",
    "            message = [{\"role\": \"system\", \"content\": f\"You are a helpful assistant. The context is {self.context}\"}] #You communicate in Thai language.\n",
    "\n",
    "        for history in self.history:\n",
    "            message.append(history)\n",
    "\n",
    "        message.append({\"role\": \"user\", \"content\": input, \"context\" : query_context})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=message,\n",
    "            max_tokens=64,\n",
    "            temperature=0.7,\n",
    "            top_p=0.7,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1,\n",
    "            stop=[\"[/INST]\",\"</s>\"],\n",
    "        )\n",
    "        print(\"Get response\")\n",
    "\n",
    "        return dict(dict(dict(response)['choices'][0])['message'])['content'].split(\"im_end\")[0].replace(\"im_start\", \"\").replace(\"assistant\",\"\").replace(\"<\",\"\").replace(\">\",\"\").replace(\"|\",\"\")\n",
    "            \n",
    "    def get_response(self, user_input):\n",
    "\n",
    "        \"\"\"Get response\n",
    "        input : \n",
    "        user_input : input from user.\n",
    "\n",
    "        output :\n",
    "        response : responser from model.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.generate_response(input = user_input)\n",
    "        except:\n",
    "            return \"Error\"\n",
    "        \n",
    "        self.update_history(user_input = user_input,bot_response = response)\n",
    "        \n",
    "        # response = self.retriever.chat(user_input)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiturnRAG:\n",
    "    def __init__(self,model, client, document_path: list, context_length : int = 20):\n",
    "        self.document_path = document_path\n",
    "        self.history = []\n",
    "        self.context_length = context_length\n",
    "        self.model = model\n",
    "        self.client = client\n",
    "\n",
    "    def initial_retriever(self):\n",
    "\n",
    "        all_doc = []\n",
    "        for path in self.document_path:\n",
    "            document = SimpleDirectoryReader(\n",
    "                input_files=[path]\n",
    "            ).load_data()\n",
    "            index = VectorStoreIndex.from_documents(document)\n",
    "            all_doc.append(index)\n",
    "\n",
    "        self.retriever  = QueryFusionRetriever(all_doc, \n",
    "                                               similarity_top_k=2, \n",
    "                                               num_queries=4,  # set this to 1 to disable query generation \n",
    "                                               use_async=True, \n",
    "                                               verbose=True,)\n",
    "\n",
    "\n",
    "    def prepare_context(self, query):\n",
    "\n",
    "        context = self.retriever.retrieve(query, top_k=self.context_length)\n",
    "        return context\n",
    "    \n",
    "    def update_history(self, user_input, bot_response):\n",
    "        self.history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        self.history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "        \n",
    "    def generate_response(self, input, context):\n",
    "        message = [{\"role\": \"system\", \"content\": \"You are a helpful assistant. You communicate in Thai language.\"}]\n",
    "\n",
    "        for history in self.history:\n",
    "            message.append(history)\n",
    "\n",
    "        message.append({\"role\": \"user\", \"content\": input})\n",
    "        print(message)\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=message,\n",
    "            max_tokens=64,\n",
    "            temperature=0.7,\n",
    "            top_p=0.7,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1,\n",
    "            stop=[\"[/INST]\",\"</s>\"],\n",
    "        )\n",
    "        print(\"Get response\")\n",
    "\n",
    "        return dict(dict(dict(response)['choices'][0])['message'])['content'].split(\"im_end\")[0].replace(\"im_start\", \"\").replace(\"assistant\",\"\").replace(\"<\",\"\").replace(\">\",\"\").replace(\"|\",\"\")\n",
    "            \n",
    "    def get_response(self, user_input):\n",
    "        response = self.generate_response(input = user_input, context=\"Normal Conversation\")\n",
    "        self.update_history(user_input = user_input,bot_response = response)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = [\"./doc/attention.pdf\"]\n",
    "    model = \"meta-llama/Meta-Llama-3-8B-Instruct-Lite\"\n",
    "    #Use for get api with llm\n",
    "    client = Together(api_key=os.environ.get('TOGETHER_API_KEY'))\n",
    "    # Start RAG OOP\n",
    "    rag = MultiturnRAG(document_path=document, model=model, client=client)\n",
    "    Input = \" \"\n",
    "    print(\"Start : \\n\")\n",
    "    while(Input != \"Exit\"):\n",
    "        Input = str(input())\n",
    "        response = rag.get_response(Input)\n",
    "        print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec env_llama in C:\\Users\\ชยพัทธ์\\AppData\\Roaming\\jupyter\\kernels\\env_llama\n"
     ]
    }
   ],
   "source": [
    "!python -m ipykernel install --user --name=env_llama"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
